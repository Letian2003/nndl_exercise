{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, datasets\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "    #normalize\n",
    "    x = x/255.0\n",
    "    x_test = x_test/255.0\n",
    "    \n",
    "    return (x, y), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel:\n",
    "    def __init__(self):\n",
    "        ####################\n",
    "        '''声明模型对应的参数'''\n",
    "        ####################\n",
    "        self.W1 = tf.Variable(tf.random.uniform([784, 84], minval=-0.1, maxval=0.1), trainable=True)\n",
    "        self.b1 = tf.Variable(tf.zeros([84]), trainable=True)\n",
    "        self.W2 = tf.Variable(tf.random.uniform([84, 10], minval=-0.1, maxval=0.1), trainable=True)\n",
    "        self.b2 = tf.Variable(tf.zeros([10]), trainable=True)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        ####################\n",
    "        '''实现模型函数体，返回未归一化的logits'''\n",
    "        ####################\n",
    "        x = tf.reshape(x, (-1, 784))\n",
    "        h1 = tf.nn.relu(x @ self.W1 + self.b1)\n",
    "        h2 = tf.nn.relu(h1 @ self.W2 + self.b2)\n",
    "        logits = h2\n",
    "\n",
    "        return logits\n",
    "        \n",
    "model = myModel()\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels))\n",
    "\n",
    "@tf.function\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(logits, y)\n",
    "\n",
    "    # compute gradient\n",
    "    trainable_vars = [model.W1, model.W2, model.b1, model.b2]\n",
    "    grads = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_vars))\n",
    "    # for g, v in zip(grads, trainable_vars):\n",
    "    #     v.assign_sub(0.01*g)\n",
    "\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    # loss and accuracy is scalar tensor\n",
    "    return loss, accuracy\n",
    "\n",
    "@tf.function\n",
    "def test(model, x, y):\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 2.30336 ; accuracy 0.100033335\n",
      "epoch 1 : loss 2.2079988 ; accuracy 0.37055\n",
      "epoch 2 : loss 2.1142883 ; accuracy 0.49508333\n",
      "epoch 3 : loss 2.0177805 ; accuracy 0.59215\n",
      "epoch 4 : loss 1.9228511 ; accuracy 0.63418335\n",
      "epoch 5 : loss 1.8321377 ; accuracy 0.6692\n",
      "epoch 6 : loss 1.7476119 ; accuracy 0.68761665\n",
      "epoch 7 : loss 1.6689857 ; accuracy 0.7046\n",
      "epoch 8 : loss 1.5958017 ; accuracy 0.71486664\n",
      "epoch 9 : loss 1.5268681 ; accuracy 0.72421664\n",
      "epoch 10 : loss 1.4608942 ; accuracy 0.73345\n",
      "epoch 11 : loss 1.397205 ; accuracy 0.742\n",
      "epoch 12 : loss 1.3364869 ; accuracy 0.7524167\n",
      "epoch 13 : loss 1.2790956 ; accuracy 0.7632667\n",
      "epoch 14 : loss 1.2258387 ; accuracy 0.7728\n",
      "epoch 15 : loss 1.1763937 ; accuracy 0.78001666\n",
      "epoch 16 : loss 1.1303355 ; accuracy 0.78718334\n",
      "epoch 17 : loss 1.0873034 ; accuracy 0.7934833\n",
      "epoch 18 : loss 1.0470201 ; accuracy 0.79981667\n",
      "epoch 19 : loss 1.0092767 ; accuracy 0.80581665\n",
      "epoch 20 : loss 0.97396743 ; accuracy 0.81013334\n",
      "epoch 21 : loss 0.9409327 ; accuracy 0.81586665\n",
      "epoch 22 : loss 0.9100179 ; accuracy 0.81888336\n",
      "epoch 23 : loss 0.8811301 ; accuracy 0.8240167\n",
      "epoch 24 : loss 0.8541097 ; accuracy 0.8264833\n",
      "epoch 25 : loss 0.82895833 ; accuracy 0.8311167\n",
      "epoch 26 : loss 0.80531394 ; accuracy 0.8323333\n",
      "epoch 27 : loss 0.783284 ; accuracy 0.8368833\n",
      "epoch 28 : loss 0.762289 ; accuracy 0.83776665\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_data, test_data \u001b[39m=\u001b[39m mnist_dataset()\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m      3\u001b[0m     loss, accuracy \u001b[39m=\u001b[39m train_one_step(model, optimizer, \n\u001b[1;32m----> 4\u001b[0m                                     tf\u001b[39m.\u001b[39;49mconstant(train_data[\u001b[39m0\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32), \n\u001b[0;32m      5\u001b[0m                                     tf\u001b[39m.\u001b[39mconstant(train_data[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint64))\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, epoch, \u001b[39m'\u001b[39m\u001b[39m: loss\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39m; accuracy\u001b[39m\u001b[39m'\u001b[39m, accuracy\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      7\u001b[0m loss, accuracy \u001b[39m=\u001b[39m test(model, \n\u001b[0;32m      8\u001b[0m                       tf\u001b[39m.\u001b[39mconstant(test_data[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32), \n\u001b[0;32m      9\u001b[0m                       tf\u001b[39m.\u001b[39mconstant(test_data[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint64))\n",
      "File \u001b[1;32md:\\Applications\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[39m=\u001b[39m signature\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[39m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32md:\\Applications\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(\n\u001b[0;32m    179\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[ops\u001b[39m.\u001b[39mOperation, ops\u001b[39m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    181\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    277\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Applications\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    288\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 289\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    291\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32md:\\Applications\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(\n\u001b[0;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[0;32m    299\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ops\u001b[39m.\u001b[39m_EagerTensorBase:\n\u001b[0;32m    300\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    302\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32md:\\Applications\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data, test_data = mnist_dataset()\n",
    "for epoch in range(50):\n",
    "    loss, accuracy = train_one_step(model, optimizer, \n",
    "                                    tf.constant(train_data[0], dtype=tf.float32), \n",
    "                                    tf.constant(train_data[1], dtype=tf.int64))\n",
    "    print('epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())\n",
    "loss, accuracy = test(model, \n",
    "                      tf.constant(test_data[0], dtype=tf.float32), \n",
    "                      tf.constant(test_data[1], dtype=tf.int64))\n",
    "\n",
    "print('test loss', loss.numpy(), '; accuracy', accuracy.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
